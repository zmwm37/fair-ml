---
title: "fairML"
author: "Zander Meitus"
date: "1/15/2021"
output: 
  powerpoint_presentation:
    reference_doc: deloitteTemplate.pptx
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## R Markdown

This is an R Markdown presentation. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.

## Slide with Bullets

- Bullet 1
- Bullet 2
- Bullet 3

## Framing the Problem

### Defintions

### Mitigating Bias vs. Quantifying Bias
Prior talk focused on ethically mitigating bias in algorithms. This talk focuses on techniques to quanitfy bias.

## History
Like many things in math and computer science, what is "new" is often pretty old. Fair ML is a hot topic, but a very similar conversation was happening in the 1960's and 1970's. [50 years of (Un)Fair Paper]

## Definitions from Corbett-Davies
- anti-classification  
- classification parity  
- calibration   

## Legal Vignette
Corbett-Davies discuss how U.S. law generally prohobits use of protected classes, which is in line with anti-classification. However, it is permitted in some cases like affirmative action. 
